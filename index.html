# <center> AutoPrep: An Automatic Preprocessing Framework for In-the-Wild Speech Data </center>

<center> Jianwei Yu<sup>1</sup>, Hangting Chen<sup>1</sup>, Yanyao Bian <sup>1</sup>, Xiang Li<sup>1</sup>, Yi Luo<sup>1</sup>, Jinchuan Tian<sup>1</sup>, Mengyang Liu<sup>1</sup>, Jiayi Jiang<sup>1</sup>, Shuai Wang<sup>2</sup></center> 
 
<center> 1 Tencent AI Lab</center>
<center> 2 Shenzhen Research Institude of Big data </center>

## Abstract
Recently, the utilization of extensive open-sourced text data has significantly advanced the performance of text-based large language models (LLMs). 
However, the use of in-the-wild large-scale speech data in the speech technology community remains constrained. 
One reason for this limitation is that a considerable amount of the publicly available speech data is compromised by background noise, speech overlapping, lack of speech segmentation information, missing speaker labels, and incomplete transcriptions, which can largely hinder their usefulness. On the other hand, human annotation of speech data is both time-consuming and costly.
To address this issue, we introduce an automatic in-the-wild speech data preprocessing framework (AutoPrep) in this paper, which is designed to enhance speech quality, generate speaker labels, and produce transcriptions automatically.
The proposed AutoPrep framework comprises six components: speech enhancement, speech segmentation, speaker clustering, target speech extraction, quality filtering and automatic speech recognition.
Experiments conducted on the open-sourced WenetSpeech and our self-collected AutoPrepWild corpora demonstrate that the proposed AutoPrep framework can generate preprocessed data with similar DNSMOS and PDNSMOS scores compared to several open-sourced TTS datasets. 
The corresponding TTS system can achieve up to 0.68 in-domain speaker similarity.

<center>
    <img style="border-radius: 0.3125em;padding:10px;background: rgb(255,255,255);
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="./assets/img/model.png">
    <br>
    <div style="border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;"> Fig.1: The diagram of the proposed full-band AutoPrep framework. </div>
</center>

## Dataset

- **AutoPrepWild**: The AutoPrepWild corpus is a collection of in-the-wild speech data that we gathered from publicly available podcasts, video recordings, and audiobooks, without segmentation, speaker labels, or text transcriptions. The original dataset consists of 680 unprocessed long audio recordings, with a total duration of approximately 498 hours. Unlike the WenetSpeech dataset, the sample rate of the AutoPrepWild corpus is either 24kHz or 44.1kHz.
- **WenetSpeech**: [WenetSpeech](https://github.com/wenet-e2e/WenetSpeech) is a widely used open-source ASR corpus, that comprises over 10,000 hours of Mandarin 16kHz speech data from diverse sources such as YouTube and Podcasts.Being derived from real-world data, WenetSpeech covers an extensive variety of acoustic conditions and includes a substantial number of speakers,  making it highly suitable for the application scenarios of AutoPrep.

## Processing results on AutoPrepWild

### Original long audio

### Examples of processing results

| Speaker ID (cluster) | Speech segment | Speech segment (enhanced) |
| :------------------: | :------------: | :-----------------------: |
| 1 | <audio src="static/samples/AutoPrepWild/spk1_0.wav" controls preload></audio> | <audio src="static/samples/AutoPrepWild/spk1_0_enhanced.wav" controls preload></audio> |
| 2 | <audio src="static/samples/AutoPrepWild/spk2_0.wav" controls preload></audio> | <audio src="static/samples/AutoPrepWild/spk2_0_enhanced.wav" controls preload></audio> |
| 3 | <audio src="static/samples/AutoPrepWild/spk3_0.wav" controls preload></audio> | <audio src="static/samples/AutoPrepWild/spk3_0_enhanced.wav" controls preload></audio> |

## Synthetic audios of AutoPrepWild speakers
| Speaker ID | Text Content | Synthetic Speech |
| :------------------: | :------------: | :-----------------------: |
| 1 | Text Content | <audio src="static/samples/AutoPrepWild/spk1_0_enhanced.wav" controls preload></audio> |
| 2 | Text Content | <audio src="static/samples/AutoPrepWild/spk2_0_enhanced.wav" controls preload></audio> |
| 3 | Text Content | <audio src="static/samples/AutoPrepWild/spk3_0_enhanced.wav" controls preload></audio> |

## Processing results on WenetSpeech

### Original long audio
<audio src="static/samples/WenetSpeech/raw.wav" controls preload></audio>

### Examples of processing results

| Speaker ID (cluster) | Speech segment | Speech segment (enhanced) |
| :------------------: | :------------: | :-----------------------: |
| 1 | <audio src="static/samples/WenetSpeech/spk1_0.wav" controls preload></audio> | <audio src="static/samples/WenetSpeech/spk1_0_enhanced.wav" controls preload></audio> |
| 2 | <audio src="static/samples/WenetSpeech/spk2_0.wav" controls preload></audio> | <audio src="static/samples/WenetSpeech/spk2_0_enhanced.wav" controls preload></audio> |
| 3 | <audio src="static/samples/WenetSpeech/spk3_0.wav" controls preload></audio> | <audio src="static/samples/WenetSpeech/spk3_0_enhanced.wav" controls preload></audio> |

## Synthetic audios of WenetSpeech speakers
| Speaker ID | Text Content | Synthetic Speech |
| :------------------: | :------------: | :-----------------------: |
| 1 | Text Content | <audio src="static/samples/WenetSpeech/spk1_0_enhanced.wav" controls preload></audio> |
| 2 | Text Content | <audio src="static/samples/WenetSpeech/spk2_0_enhanced.wav" controls preload></audio> |
| 3 | Text Content | <audio src="static/samples/WenetSpeech/spk3_0_enhanced.wav" controls preload></audio> |